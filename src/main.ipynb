{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADITYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADITYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Download necessary NLTK data \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset path (update this path to where your CSV file is located)\n",
    "dataset_path = '../data/spotify_songs.csv'\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove any character that is not a letter or whitespace\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space and strip leading/trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "    words = [word for word in text.split() if word not in stopword_list]\n",
    "    \n",
    "    # Initialize Snowball Stemmer for stemming words to their root form\n",
    "    sb_stem = SnowballStemmer('english')\n",
    "    words = [sb_stem.stem(word) for word in words]\n",
    "    \n",
    "    # Rejoin the list of words into a single string\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>look face wonder face mean someth special look...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>take easi pleas touch gentl like summer even b...</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>ill never know go put lousi rotten show boy to...</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>make somebodi happi question give take learn s...</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  text_length  \n",
       "0  look face wonder face mean someth special look...          365  \n",
       "1  take easi pleas touch gentl like summer even b...          804  \n",
       "2  ill never know go put lousi rotten show boy to...          680  \n",
       "3  make somebodi happi question give take learn s...          817  \n",
       "4  make somebodi happi question give take learn s...          835  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the cleaning function to the 'text' column\n",
    "df['text'] = df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "# Optionally, add a column with the length of each cleaned text\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "\n",
    "# Display the first few rows to inspect changes\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of cleaned song lyrics\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(query):\n",
    "    \"\"\"\n",
    "    Given a lyric snippet (query), vectorize the query using the same TF-IDF vectorizer,\n",
    "    compute cosine similarity with the TF-IDF matrix, and return the index and similarity score.\n",
    "    \"\"\"\n",
    "    # Clean the query text using the same cleaning function\n",
    "    query_clean = clean_text(query)\n",
    "    query_vector = vectorizer.transform([query_clean])\n",
    "    \n",
    "    # Compute cosine similarity between the query vector and all song vectors\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    \n",
    "    # Identify the best matching song (highest similarity score)\n",
    "    best_index = similarities.argmax()\n",
    "    best_score = similarities[0, best_index]\n",
    "    return best_index, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Match:\n",
      "Song Row: 970\n",
      "Artist: Backstreet Boys\n",
      "Song: Everytime I Close My Eyes\n",
      "Similarity Score: 0.313454239068443\n"
     ]
    }
   ],
   "source": [
    "# Example lyric snippet (modify as needed)\n",
    "query_lyric = \"Listen girl, I don't know where to start Cause every word I say is straight from the heart I've\"\n",
    "\n",
    "# Find the best match for the provided lyric snippet\n",
    "best_index, score = find_best_match(query_lyric)\n",
    "\n",
    "# Retrieve the best matching song details\n",
    "best_match = df.iloc[best_index]\n",
    "\n",
    "print(\"Best Match:\")\n",
    "print(\"Song Row:\", best_index)\n",
    "print(\"Artist:\", best_match['artist'])\n",
    "print(\"Song:\", best_match['song'])\n",
    "print(\"Similarity Score:\", score)\n",
    "# print(\"Link:\", best_match['link'])\n",
    "# print(\"Lyrics:\", best_match['text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 3 Matches:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three Matches:\n",
      "\n",
      "Song Row: 970\n",
      "Artist: Backstreet Boys\n",
      "Song: Everytime I Close My Eyes\n",
      "Similarity Score: 0.313454239068443\n",
      "\n",
      "Song Row: 594\n",
      "Artist: Allman Brothers Band\n",
      "Song: Straight From The Heart\n",
      "Similarity Score: 0.2931339247022677\n",
      "\n",
      "Song Row: 35380\n",
      "Artist: Hanson\n",
      "Song: Every Word I Say\n",
      "Similarity Score: 0.2182599569590553\n"
     ]
    }
   ],
   "source": [
    "def find_top_matches(query, top_n=3):\n",
    "    \"\"\"\n",
    "    Given a lyric snippet, this function cleans and vectorizes the query,\n",
    "    computes cosine similarity with the TF-IDF matrix, and returns the top N\n",
    "    matching songs as a list of tuples (song_index, similarity_score).\n",
    "    \"\"\"\n",
    "    # Clean the query text using the same cleaning function\n",
    "    query_clean = clean_text(query)\n",
    "    query_vector = vectorizer.transform([query_clean])\n",
    "    \n",
    "    # Compute cosine similarity between the query vector and all song vectors\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get indices of the top N scores in descending order\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "    top_scores = similarities[top_indices]\n",
    "    \n",
    "    return list(zip(top_indices, top_scores))\n",
    "\n",
    "# Example lyric snippet (modify as needed)\n",
    "# query_lyric = \"sing us a song you're the piano man sing us a song tonight\"\n",
    "\n",
    "# Get the top three matches for the query lyric\n",
    "top_matches = find_top_matches(query_lyric, top_n=3)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top Three Matches:\")\n",
    "for idx, score in top_matches:\n",
    "    match = df.iloc[idx]\n",
    "    print(\"\\nSong Row:\", idx)\n",
    "    print(\"Artist:\", match['artist'])\n",
    "    print(\"Song:\", match['song'])\n",
    "    # print(\"Link:\", match['link'])\n",
    "    # print(\"Lyrics:\", match['text'])\n",
    "    print(\"Similarity Score:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
