{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Download necessary NLTK data (run these lines once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset path (update this path to where your CSV file is located)\n",
    "dataset_path = '../data/spotify_songs.csv'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head() \n",
    "# df.shape\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove any character that is not a letter or whitespace\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space and strip leading/trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "    words = [word for word in text.split() if word not in stopword_list]\n",
    "    \n",
    "    # Initialize Snowball Stemmer for stemming words to their root form\n",
    "    sb_stem = SnowballStemmer('english')\n",
    "    words = [sb_stem.stem(word) for word in words]\n",
    "    \n",
    "    # Rejoin the list of words into a single string\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the 'text' column\n",
    "df['text'] = df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "# Optionally, add a column with the length of each cleaned text\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "\n",
    "# Display the first few rows to inspect changes\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of cleaned song lyrics\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "# Create a TF-IDF vectorizer instance\n",
    "# (You can remove 'stop_words' here if cleaning already removed them)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(query):\n",
    "    \"\"\"\n",
    "    Given a lyric snippet (query), vectorize the query using the same TF-IDF vectorizer,\n",
    "    compute cosine similarity with the TF-IDF matrix, and return the index and similarity score.\n",
    "    \"\"\"\n",
    "    # Clean the query text using the same cleaning function\n",
    "    query_clean = clean_text(query)\n",
    "    query_vector = vectorizer.transform([query_clean])\n",
    "    \n",
    "    # Compute cosine similarity between the query vector and all song vectors\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
    "    \n",
    "    # Identify the best matching song (highest similarity score)\n",
    "    best_index = similarities.argmax()\n",
    "    best_score = similarities[0, best_index]\n",
    "    return best_index, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example lyric snippet (modify as needed)\n",
    "query_lyric = \"Listen girl, I don't know where to start Cause every word I say is straight from the heart I've\"\n",
    "\n",
    "# Find the best match for the provided lyric snippet\n",
    "best_index, score = find_best_match(query_lyric)\n",
    "\n",
    "# Retrieve the best matching song details\n",
    "best_match = df.iloc[best_index]\n",
    "\n",
    "print(\"Best Match:\")\n",
    "print(\"Song Row:\", best_index)\n",
    "print(\"Artist:\", best_match['artist'])\n",
    "print(\"Song:\", best_match['song'])\n",
    "print(\"Similarity Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Link:\", best_match['link'])\n",
    "print(\"Lyrics:\", best_match['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_top_matches(query, top_n=3):\n",
    "    \"\"\"\n",
    "    Given a lyric snippet, this function cleans and vectorizes the query,\n",
    "    computes cosine similarity with the TF-IDF matrix, and returns the top N\n",
    "    matching songs as a list of tuples (song_index, similarity_score).\n",
    "    \"\"\"\n",
    "    # Clean the query text using the same cleaning function\n",
    "    query_clean = clean_text(query)\n",
    "    query_vector = vectorizer.transform([query_clean])\n",
    "    \n",
    "    # Compute cosine similarity between the query vector and all song vectors\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get indices of the top N scores in descending order\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "    top_scores = similarities[top_indices]\n",
    "    \n",
    "    return list(zip(top_indices, top_scores))\n",
    "\n",
    "# Example lyric snippet (modify as needed)\n",
    "# query_lyric = \"sing us a song you're the piano man sing us a song tonight\"\n",
    "\n",
    "# Get the top three matches for the query lyric\n",
    "top_matches = find_top_matches(query_lyric, top_n=3)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top Three Matches:\")\n",
    "for idx, score in top_matches:\n",
    "    match = df.iloc[idx]\n",
    "    print(\"\\nSong Row:\", idx)\n",
    "    print(\"Artist:\", match['artist'])\n",
    "    print(\"Song:\", match['song'])\n",
    "    # print(\"Link:\", match['link'])\n",
    "    # print(\"Lyrics:\", match['text'])\n",
    "    print(\"Similarity Score:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
